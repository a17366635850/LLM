说明文件：vllm部署qwen3，需要本地下载好的模型。

1.单卡部署：
配置环境，执行单卡部署命令，把端口开放到本地（不是连接服务器），使用控制台服务器的自定义服务的第二个，使用cmd输入命令，第一个6006改为8000，输入密码（复制不正确的话手动），挂载成功，然后在本地运行url_demo，
url ="http://localhost:8880/v1/chat/completions",修改模型名称，运行。

2.openai单卡部署：
执行openai部署命令，把端口开放到本地（不是连接服务器），使用控制台服务器的自定义服务的第二个，使用cmd输入命令，第一个6006改为8000，输入密码（复制不正确的话手动），挂载成功，然后在本地运行openai-demo

3.多卡部署：
执行多卡部署命令，把端口开放到本地（不是连接服务器），使用控制台服务器的自定义服务的第二个，使用cmd输入命令，第一个6006改为8000，输入密码（复制不正确的话手动），挂载成功，然后在本地运行url_demo，
url ="http://localhost:8880/v1/chat/completions",修改模型名称，运行。
